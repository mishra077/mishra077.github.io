<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://mishra077.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://mishra077.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-04-16T13:15:00+00:00</updated><id>https://mishra077.github.io/feed.xml</id><title type="html">Abhishek Mishra</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</title><link href="https://mishra077.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/" rel="alternate" type="text/html" title="Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra"/><published>2024-05-14T00:00:00+00:00</published><updated>2024-05-14T00:00:00+00:00</updated><id>https://mishra077.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra</id><content type="html" xml:base="https://mishra077.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[We’re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.]]></summary></entry><entry><title type="html">Research Insights on Copyright Protection in AI-Generated Images</title><link href="https://mishra077.github.io/blog/2024/research-insights/" rel="alternate" type="text/html" title="Research Insights on Copyright Protection in AI-Generated Images"/><published>2024-05-01T00:00:00+00:00</published><updated>2024-05-01T00:00:00+00:00</updated><id>https://mishra077.github.io/blog/2024/research-insights</id><content type="html" xml:base="https://mishra077.github.io/blog/2024/research-insights/"><![CDATA[<h1 id="research-insights-copyright-protection-in-ai-image-generation">Research Insights: Copyright Protection in AI Image Generation</h1> <p>This blog post explores some of the mathematical concepts underlying our recent work on “Guardians of Generation: Dynamic Inference-Time Copyright Shielding with Adaptive Guidance for AI Image Generation.”</p> <h2 id="problem-formulation">Problem Formulation</h2> <p>Let’s define the problem mathematically. Given a diffusion model \(f_\theta\) and a copyright-protected reference image \(I_r\), we aim to prevent the generation of images \(I_g\) that are too similar to \(I_r\) according to some similarity metric \(\mathcal{S}(I_g, I_r)\).</p> <p>The generation process can be formulated as:</p> \[I_g = f_\theta(z, c, t)\] <p>Where:</p> <ul> <li>\(z\) is the noise input</li> <li>\(c\) is the conditioning (e.g., text prompt)</li> <li>\(t\) represents the timesteps in the diffusion process</li> </ul> <h2 id="adaptive-guidance-mechanism">Adaptive Guidance Mechanism</h2> <p>Our approach introduces an adaptive guidance mechanism that modifies the generation process:</p> \[\tilde{f}_\theta(z, c, t) = f_\theta(z, c, t) - \lambda(t) \nabla_{I_t} \mathcal{S}(I_t, I_r)\] <p>Where:</p> <ul> <li>\(I_t\) is the intermediate generated image at timestep \(t\)</li> <li>\(\lambda(t)\) is a dynamic weight function that varies with the timestep</li> <li>\(\nabla_{I_t} \mathcal{S}(I_t, I_r)\) is the gradient of the similarity with respect to the current image</li> </ul> <p>The adaptive function \(\lambda(t)\) is defined as:</p> \[\lambda(t) = \begin{cases} \alpha \cdot \left(1 - \frac{t}{T}\right)^\beta &amp; \text{if } \mathcal{S}(I_t, I_r) &gt; \tau \\ 0 &amp; \text{otherwise} \end{cases}\] <p>Where:</p> <ul> <li>\(\alpha\) controls the overall strength of the guidance</li> <li>\(\beta\) controls how quickly the guidance increases as \(t\) decreases</li> <li>\(\tau\) is a threshold for when to apply the guidance</li> <li>\(T\) is the total number of timesteps</li> </ul> <h2 id="similarity-metrics">Similarity Metrics</h2> <p>We explored several similarity metrics \(\mathcal{S}\), including:</p> <ol> <li><strong>CLIP Similarity</strong>:</li> </ol> \[\mathcal{S}_{\text{CLIP}}(I_1, I_2) = \frac{E_{\text{CLIP}}(I_1) \cdot E_{\text{CLIP}}(I_2)}{||E_{\text{CLIP}}(I_1)|| \cdot ||E_{\text{CLIP}}(I_2)||}\] <ol> <li><strong>Structural Similarity Index (SSIM)</strong>:</li> </ol> \[\mathcal{S}_{\text{SSIM}}(I_1, I_2) = \frac{(2\mu_{I_1}\mu_{I_2} + C_1)(2\sigma_{I_1 I_2} + C_2)}{(\mu_{I_1}^2 + \mu_{I_2}^2 + C_1)(\sigma_{I_1}^2 + \sigma_{I_2}^2 + C_2)}\] <ol> <li><strong>Perceptual Loss</strong>:</li> </ol> \[\mathcal{S}_{\text{Perceptual}}(I_1, I_2) = \sum_{l} w_l \cdot ||F_l(I_1) - F_l(I_2)||_2^2\] <p>Where \(F_l\) represents the activations at layer \(l\) of a pre-trained network.</p> <h2 id="experimental-results">Experimental Results</h2> <p>Our method achieves a balance between copyright protection and generation quality. We measured this using:</p> \[\text{Protection Rate} = \frac{n_{\text{protected}}}{n_{\text{total}}} \times 100\%\] \[\text{Quality Preservation} = \frac{1}{n} \sum_{i=1}^{n} \mathcal{Q}(I_i, c_i)\] <p>Where \(\mathcal{Q}\) is a quality metric comparing the generated image to the conditioning.</p> <h2 id="future-directions">Future Directions</h2> <p>Future work includes optimizing the adaptive function \(\lambda(t)\) through reinforcement learning:</p> \[\lambda_{\phi}^*(t) = \arg\max_{\phi} \mathbb{E}_{z,c}[R(f_\theta, \lambda_{\phi}, z, c, I_r)]\] <p>Where \(R\) is a reward function balancing protection and quality, and \(\phi\) are the parameters of the dynamic weight function.</p> <p>This approach promises to provide more nuanced control over the copyright protection mechanism while maintaining generation quality.</p>]]></content><author><name>Abhishek Mishra</name></author><summary type="html"><![CDATA[An exploration of the mathematical foundations behind dynamic inference-time copyright shielding]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mishra077.github.io/assets/img/12.jpg"/><media:content medium="image" url="https://mishra077.github.io/assets/img/12.jpg" xmlns:media="http://search.yahoo.com/mrss/"/></entry><entry><title type="html">LaTeX Math Examples for AI Research</title><link href="https://mishra077.github.io/blog/2023/latex-example/" rel="alternate" type="text/html" title="LaTeX Math Examples for AI Research"/><published>2023-12-01T00:00:00+00:00</published><updated>2023-12-01T00:00:00+00:00</updated><id>https://mishra077.github.io/blog/2023/latex-example</id><content type="html" xml:base="https://mishra077.github.io/blog/2023/latex-example/"><![CDATA[<h1 id="latex-math-examples-for-ai-research">LaTeX Math Examples for AI Research</h1> <p>This post demonstrates how LaTeX can be used to express complex mathematical concepts in AI research.</p> <h2 id="fundamental-equations">Fundamental Equations</h2> <p>Einstein’s famous equation states that \(E = mc^2\), which relates energy (\(E\)), mass (\(m\)), and the speed of light (\(c\)).</p> <p>The Pythagorean theorem can be expressed as \(a^2 + b^2 = c^2\).</p> <h2 id="neural-networks">Neural Networks</h2> <p>The activation of a neuron in a neural network can be computed as:</p> \[a = \sigma\left(\sum_{i=1}^{n} w_i x_i + b\right)\] <p>Where:</p> <ul> <li>\(\sigma\) is the activation function</li> <li>\(w_i\) are the weights</li> <li>\(x_i\) are the inputs</li> <li>\(b\) is the bias</li> </ul> <h2 id="deep-learning">Deep Learning</h2> <p>The cross-entropy loss function commonly used in classification:</p> \[L = -\frac{1}{N}\sum_{i=1}^{N}\sum_{j=1}^{C}y_{ij}\log(p_{ij})\] <p>Where:</p> <ul> <li>\(N\) is the number of samples</li> <li>\(C\) is the number of classes</li> <li>\(y_{ij}\) is a binary indicator if class \(j\) is the correct classification for sample \(i\)</li> <li>\(p_{ij}\) is the predicted probability that sample \(i\) belongs to class \(j\)</li> </ul> <h2 id="statistical-formulas">Statistical Formulas</h2> <p>The normal distribution probability density function:</p> \[f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}\] <p>Where \(\mu\) is the mean and \(\sigma\) is the standard deviation.</p> <h2 id="optimization">Optimization</h2> <p>Gradient descent update rule:</p> \[\theta_{t+1} = \theta_t - \alpha \nabla_\theta J(\theta_t)\] <p>Where:</p> <ul> <li>\(\theta_t\) is the parameter at time step \(t\)</li> <li>\(\alpha\) is the learning rate</li> <li>\(\nabla_\theta J(\theta_t)\) is the gradient of the cost function</li> </ul>]]></content><author><name>Abhishek Mishra</name></author><summary type="html"><![CDATA[A showcase of essential mathematical formulations used in artificial intelligence and machine learning research]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://mishra077.github.io/assets/img/8.jpg"/><media:content medium="image" url="https://mishra077.github.io/assets/img/8.jpg" xmlns:media="http://search.yahoo.com/mrss/"/></entry><entry><title type="html">Displaying External Posts on Your al-folio Blog</title><link href="https://mishra077.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/" rel="alternate" type="text/html" title="Displaying External Posts on Your al-folio Blog"/><published>2022-04-23T23:20:09+00:00</published><updated>2022-04-23T23:20:09+00:00</updated><id>https://mishra077.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog</id><content type="html" xml:base="https://mishra077.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/"><![CDATA[]]></content><author><name></name></author></entry></feed>